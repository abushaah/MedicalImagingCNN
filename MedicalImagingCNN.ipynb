{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1327578,"sourceType":"datasetVersion","datasetId":767686},{"sourceId":1327590,"sourceType":"datasetVersion","datasetId":769463}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T23:59:17.725593Z","iopub.execute_input":"2025-07-06T23:59:17.726003Z","iopub.status.idle":"2025-07-06T23:59:21.036688Z","shell.execute_reply.started":"2025-07-06T23:59:17.725975Z","shell.execute_reply":"2025-07-06T23:59:21.035938Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.5.0)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nfrom glob import glob\nimport psutil\n\n\"\"\"\n    Get data inputs, assumes CT volumes and segmentation masks have corresponding names and indices.\n    Analyze the nifti datasets for MONAI parameter adjustments\n    :param str in_dir: file path of data.\n\"\"\"\ndef prepare_and_configure(in_dir):\n    volume_dict = {}\n    segmentation_dict = {}\n\n    # find all .nii files under in_dir\n    nii_files = glob(os.path.join(in_dir, \"**\", \"*.nii\"), recursive=True)\n\n    for filepath in nii_files:\n        filename = os.path.basename(filepath)\n        if filename.startswith(\"volume-\"):\n            idx = int(filename.split(\"-\")[1].split(\".\")[0])\n            volume_dict[idx] = filepath\n        elif filename.startswith(\"segmentation-\"):\n            idx = int(filename.split(\"-\")[1].split(\".\")[0])\n            segmentation_dict[idx] = filepath\n\n    # match volume and segmentation by idx\n    \n    # matched_keys = sorted(set(volume_dict.keys()) & set(segmentation_dict.keys()))\n    # test model syntax first\n    matched_keys = sorted(set(volume_dict.keys()) & set(segmentation_dict.keys()))[:10]\n\n    all_files = [{\"image\": volume_dict[k], \"label\": segmentation_dict[k]} for k in matched_keys]\n\n    # split 80% train / 20% validation\n    split_idx = int(0.8 * len(all_files))\n    train_files = all_files[:split_idx]\n    validation_files = all_files[split_idx:]\n    \n    # analyze voxel sizes and shapes\n    voxel_sizes = []\n    shapes = []\n    for k in matched_keys:\n        img = nib.load(volume_dict[k])\n        data = img.get_fdata()\n        voxel_sizes.append(img.header.get_zooms())\n        shapes.append(data.shape)\n\n    # pixdim based on variables in https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d.ipynb\n    mean_spacing = np.mean(voxel_sizes, axis=0)\n    mean_shape = np.mean(shapes, axis=0)\n    pixdim = tuple(round(s, 2) for s in mean_spacing)\n\n    # default for soft tissue\n    a_min, a_max = -200, 250\n\n    # detect GPU & RAM memory\n    try:\n        import GPUtil\n        gpus = GPUtil.getGPUs()\n        mem_free_gpu = max([gpu.memoryFree for gpu in gpus])  # in MB\n    except Exception:\n        mem_free_gpu = 0  # fallback to CPU\n\n    mem_free_ram = psutil.virtual_memory().available // (1024 * 1024)\n\n    # adjust preprocessing resolution based on memory\n    # values are randomized based on https://docs.monai.io/en/stable/transforms.html\n    if mem_free_gpu >= 20000:\n        spatial_size = [256, 256, 256]\n        batch_size = 2\n    elif mem_free_gpu >= 10000:\n        spatial_size = [192, 192, 128]\n        batch_size = 1\n    elif mem_free_gpu >= 4000:\n        spatial_size = [128, 128, 64]\n        batch_size = 1\n    else:\n        spatial_size = [96, 96, 64]\n        batch_size = 1\n\n    return {\n        \"train_files\": train_files,\n        \"validation_files\": validation_files,\n        \"pixdim\": pixdim,\n        \"a_min\": a_min,\n        \"a_max\": a_max,\n        \"spatial_size\": spatial_size,\n        \"batch_size\": batch_size,\n        \"mem_free_gpu\": mem_free_gpu,\n        \"mem_free_ram\": mem_free_ram,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T23:59:21.038493Z","iopub.execute_input":"2025-07-06T23:59:21.038851Z","iopub.status.idle":"2025-07-06T23:59:21.050133Z","shell.execute_reply.started":"2025-07-06T23:59:21.038816Z","shell.execute_reply":"2025-07-06T23:59:21.049464Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import re\nfrom glob import glob\nfrom monai.transforms import (\n    Compose,\n    EnsureChannelFirstD,\n    LoadImaged,\n    Resized,\n    ToTensord,\n    Spacingd,\n    Orientationd,\n    ScaleIntensityRanged,\n    CropForegroundd,\n    RandCropByPosNegLabeld,\n)\nfrom monai.data import DataLoader, Dataset, CacheDataset\nfrom monai.utils import set_determinism\n\n\"\"\"\n    Use MONAI transforms to prepares data for segmentation.\n    Voxel: 3D grid representation of data.\n    \n    :param tuple pixdim: standard voxel spacing (in millimeters) for resampling the images in the x, y, and z dimensions.\n    :param int a_min: intensity voxel min for CT scans (less are clipped before scaling).\n    :param int a_max: intensity voxel max for CT scans (more are clipped before scaling).\n    :param int array spatial_size: output size (in voxel) to which each image and label volume will be resized. AKA input size for the neural network.\n    :param int batch_size: adjyst batch size, default is 1.\n    :return PyTorch DataLoader objects: used to train neural network.\n\"\"\"\ndef preprocess(pixdim, a_min, a_max, spatial_size, batch_size, cache, train_files, validation_files):\n\n    # reproduce training results\n    set_determinism(seed=0)\n\n    # and apply transformations to them\n    # parameters from https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d.ipynb\n    train_transforms = Compose([\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstD(keys=[\"image\", \"label\"]),\n        ScaleIntensityRanged(keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\", \"label\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n        RandCropByPosNegLabeld(\n            keys=[\"image\", \"label\"],\n            label_key=\"label\",\n            spatial_size=spatial_size,  # use your configured size here\n            pos=1, neg=1,\n            num_samples=4,\n            image_key=\"image\",\n            image_threshold=0,\n        ),\n        ToTensord(keys=[\"image\", \"label\"]),\n    ])\n\n    # transforms for validation data\n    validation_transforms = Compose([\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstD(keys=[\"image\", \"label\"]),\n        ScaleIntensityRanged(keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\", \"label\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n    ])\n\n    if cache is not None and cache >= 16000:\n        train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\n        validation_ds = CacheDataset(data=validation_files, transform=validation_transforms, cache_rate=1.0)\n\n        # train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n        # validation_ds = CacheDataset(data=validation_files, transform=validation_transforms, cache_rate=1.0, num_workers=4)\n    else:\n        train_ds = Dataset(data=train_files, transform=train_transforms)\n        validation_ds = Dataset(data=validation_files, transform=validation_transforms)\n\n        # train_ds = Dataset(data=train_files, transform=train_transforms, num_workers=4)\n        # validation_ds = Dataset(data=validation_files, transform=validation_transforms, num_workers=4)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size)\n    validation_loader = DataLoader(validation_ds, batch_size=batch_size)\n\n    # use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n    # train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n    # validation_loader = DataLoader(validation_ds, batch_size=batch_size, num_workers=4)\n\n    return train_loader, validation_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T23:59:21.050975Z","iopub.execute_input":"2025-07-06T23:59:21.051257Z","iopub.status.idle":"2025-07-06T23:59:21.075596Z","shell.execute_reply.started":"2025-07-06T23:59:21.051233Z","shell.execute_reply":"2025-07-06T23:59:21.074800Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot(epoch_loss_values, val_interval, metric_values):\n    plt.figure(\"train\", (12, 6))\n    plt.subplot(1, 2, 1)\n    plt.title(\"Epoch Average Loss\")\n    x = [i + 1 for i in range(len(epoch_loss_values))]\n    y = epoch_loss_values\n    plt.xlabel(\"epoch\")\n    plt.plot(x, y)\n    plt.subplot(1, 2, 2)\n    plt.title(\"Val Mean Dice\")\n    x = [val_interval * (i + 1) for i in range(len(metric_values))]\n    y = metric_values\n    plt.xlabel(\"epoch\")\n    plt.plot(x, y)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T23:59:21.077021Z","iopub.execute_input":"2025-07-06T23:59:21.077213Z","iopub.status.idle":"2025-07-06T23:59:21.097092Z","shell.execute_reply.started":"2025-07-06T23:59:21.077200Z","shell.execute_reply":"2025-07-06T23:59:21.096392Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from monai.transforms import (\n    AsDiscrete,\n    Compose,\n)\nfrom torch.cuda.amp import GradScaler, autocast\n\ndef train (model, loss_function, optimizer, dice_metric, train_loader, validation_loader):\n    max_epochs = 600\n    val_interval = 2\n    best_metric = -1\n    best_metric_epoch = -1\n    epoch_loss_values = []\n    metric_values = []\n    post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n    post_label = Compose([AsDiscrete(to_onehot=2)])\n    scaler = GradScaler()\n    \n    for epoch in range(max_epochs):\n        print(\"-\" * 10)\n        print(f\"epoch {epoch + 1}/{max_epochs}\")\n        model.train()\n        epoch_loss = 0\n        step = 0\n        for batch_data in train_loader:\n            step += 1\n            inputs, labels = (\n                batch_data[\"image\"].to(device),\n                batch_data[\"label\"].to(device).long(),\n                # batch_data[\"label\"].to(device),\n            )\n\n            print(\"Label shape:\", labels.shape)\n            print(\"Label dtype:\", labels.dtype)\n            print(\"Label unique values:\", torch.unique(labels))\n\n            optimizer.zero_grad()\n            with autocast():\n                outputs = model(inputs)\n                loss = loss_function(outputs, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n                \n            # loss.backward()\n            # optimizer.step()\n            print(f\"loss.item: {loss.item()}\")\n            epoch_loss += loss.item()\n            print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n        epoch_loss /= step\n        epoch_loss_values.append(epoch_loss)\n        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n    \n        if (epoch + 1) % val_interval == 0:\n            model.eval()\n            with torch.no_grad():\n                for val_data in val_loader:\n                    val_inputs, val_labels = (\n                        val_data[\"image\"].to(device),\n                        val_data[\"label\"].to(device).long(),\n                        # val_data[\"label\"].to(device),\n                    )\n                    # roi_size = (160, 160, 160)\n                    roi_size = (64, 64, 64)\n                    sw_batch_size = 4\n                    val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n                    val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n                    val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n                    # compute metric for current iteration\n                    dice_metric(y_pred=val_outputs, y=val_labels)\n\n                    # free memory\n                    del val_inputs, val_labels, val_outputs\n                    torch.cuda.empty_cache()\n    \n                # aggregate the final mean dice result\n                metric = dice_metric.aggregate().item()\n                # reset the status for next validation round\n                dice_metric.reset()\n    \n                metric_values.append(metric)\n                if metric > best_metric:\n                    best_metric = metric\n                    best_metric_epoch = epoch + 1\n                    torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n                    print(\"saved new best metric model\")\n                print(\n                    f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n                    f\"\\nbest mean dice: {best_metric:.4f} \"\n                    f\"at epoch: {best_metric_epoch}\"\n                )\n                \n    print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")\n    plot(epoch_loss_values, val_interval, metric_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T00:02:22.934101Z","iopub.execute_input":"2025-07-07T00:02:22.934393Z","iopub.status.idle":"2025-07-07T00:02:22.945854Z","shell.execute_reply.started":"2025-07-07T00:02:22.934373Z","shell.execute_reply":"2025-07-07T00:02:22.945129Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceLoss\nfrom monai.metrics import DiceMetric\nfrom monai.networks.layers import Norm\n\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\nif __name__ == '__main__':\n    \n    # 1. user input (for now, it is kaggle data set)\n    print(\"Preparing dataset directory and machine specifications...\")\n    params = prepare_and_configure(in_dir=\"/kaggle/input\")\n    print(\"Complete\")\n    \n    # show output\n    # print(\"prepare_and_configure:\")\n    # for k, v in params.items():\n    #     print(f\"{k}: {v}\")\n    \n    # 2. preprocess\n    print(\"Preprocess dataset with MONAI transforms...\")\n    train_loader, validation_loader = preprocess(pixdim=params['pixdim'], a_min=params['a_min'], a_max=params['a_max'], spatial_size=params['spatial_size'], batch_size=params['batch_size'], cache=params['mem_free_ram'], train_files=params['train_files'], validation_files=params['validation_files'])\n    # print(train_loader)\n    # print(validation_loader)\n    print(\"Complete\")\n\n    # 3. build U-net\n    print(\"Building U-Net Model...\")\n    device = torch.device(\"cuda:0\")\n    model = UNet(\n        spatial_dims=3,\n        in_channels=1,\n        out_channels=2,\n        channels=(8, 16, 32, 64),\n        strides=(2, 2, 2, 2),\n        num_res_units=1,\n        norm=Norm.BATCH,\n    ).to(device)\n    print(\"Complete\")\n\n    print(\"Evaluating model parameters...\")\n    loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n    optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n    print(\"Complete\")\n\n    # 4. train\n    print(\"Training model...\")\n    train(model, loss_function, optimizer, dice_metric, train_loader, validation_loader)\n    print(\"Complete\")\n\n    # 5. test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T00:05:45.985154Z","iopub.execute_input":"2025-07-07T00:05:45.985876Z","iopub.status.idle":"2025-07-07T00:05:48.940027Z","shell.execute_reply.started":"2025-07-07T00:05:45.985853Z","shell.execute_reply":"2025-07-07T00:05:48.938824Z"}},"outputs":[{"name":"stdout","text":"Preparing dataset directory and machine specifications...\nComplete\nPreprocess dataset with MONAI transforms...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1589628470.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 2. preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocess dataset with MONAI transforms...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixdim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spatial_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mem_free_ram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# print(train_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# print(validation_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3445120979.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(pixdim, a_min, a_max, spatial_size, batch_size, cache, train_files, validation_files)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# reproduce training results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mset_determinism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# and apply transformations to them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/utils/misc.py\u001b[0m in \u001b[0;36mset_determinism\u001b[0;34m(seed, use_deterministic_algorithms, additional_settings)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mMAX_SEED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":25}]}